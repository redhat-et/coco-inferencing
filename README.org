* Confidential Inferencing

Experimenting with encrypted model delivery into a confidential inferencing environment.

** Approach

Use an init container to copy the model image from a registry into ramdisk inside the
confidential container.

** Steps

1. Run ~make kind~ to start a kind cluster
2. Run ~make init-container~ to build the init-container image
3. Run ~make run~ to run the inference pod

** Usage

#+begin_src sh
% make
fetch                Fetch image from Huggingface
oci                  Build OCI artifact for model
push                 Push OCI artifact to registry
gen-keys             Generate crypto keypair
encrypt              Encrypt the model (registry -> registry)
decrypt              Decrypt the modek (registry -> registry)
pull                 Pull and extract model from registry
kind                 Start a kind cluster
init-container       Build the init container
run                  Run the inferencing pod
clean                Clean everything up, also deleting the kind cluster
configure-machine    Configure podman machine to use insecure registry
help                 This help
#+end_src

Note: when using a podman machine it needs space for an 8GB ramdisk in addition to the
kubernetes pods.

#+begin_src sh
podman machine init --cpus 8 --memory 16384
#+end_src

** Model packaging as OCI artifact

*** Fetch model and package as OCI

#+begin_src sh
huggingface-cli download Qwen/Qwen3-0.6B --local-dir model

modctl modelfile generate model
modctl build -t tosh.lan:5000/qwen/qwen3-0.6b:latest -f Modelfile model
modctl push --plain-http tosh.lan:5000/qwen/qwen3-0.6b:latest
#+end_src

*** Encrypt model with skopeo

#+begin_src sh
openssl genpkey -algorithm RSA -out private.pem -pkeyopt rsa_keygen_bits:4096
openssl rsa -pubout -in private.pem -out public.pem

skopeo copy --encryption-key jwe:public.pem \
	docker://tosh.lan:5000/qwen/qwen3-0.6b:latest \
	docker://tosh.lan:5000/qwen/qwen3-0.6b:encrypted
#+end_src

*** Decrypt model with skopeo

#+begin_src sh
skopeo copy --decryption-key private.pem \
	docker://tosh.lan:5000/qwen/qwen3-0.6b:encrypted \
	dir:decrypted
#+end_src

*** Unpack OCI into usable model

#+begin_src sh :results output
mkdir ramdisk
for layer in `jq -r '.layers[] | .digest' decrypted/manifest.json`
do
    tar xvf decrypted/${layer:7} -C ramdisk
done
#+end_src

#+RESULTS:
: config.json
: generation_config.json
: tokenizer.json
: tokenizer_config.json
: vocab.json
: model.safetensors
: LICENSE
: README.md
: merges.txt

*** Serve model with vLLM

#+begin_src sh
vllm serve /ramdisk
#+end_src

